{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalAveragePooling1D, Input, Activation, \\\n",
    "    BatchNormalization, MaxPooling1D, concatenate\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_embedding_RedDNN(max_len=1600, embedding_size=8):\n",
    "    now_pay_input_layer = Input((max_len, ), name='now_pay')\n",
    "    embedding_layer = Embedding(257, embedding_size)(now_pay_input_layer)\n",
    "    x = Conv1D(32, 3)(embedding_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=[now_pay_input_layer], outputs=output_layer)\n",
    "\n",
    "def one_hot_RedDNN(max_len=1600):\n",
    "    now_pay_input_layer = Input((max_len, 257), name='now_pay')\n",
    "    x = Conv1D(32, 3)(now_pay_input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=[now_pay_input_layer], outputs=output_layer)\n",
    "\n",
    "def div_256_RedDNN(max_len=1600):\n",
    "    now_pay_input_layer = Input((max_len, 1), name='now_pay')\n",
    "    x = Conv1D(32, 3)(now_pay_input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(16)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "    return Model(inputs=[now_pay_input_layer], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def keras_embedding_preprocessing_payload(payloads, max_len=1600):\n",
    "    tmp = []\n",
    "    for payload in tqdm(payloads):\n",
    "        byte_payload = []\n",
    "        for i in range(0, len(payload), 2):\n",
    "            byte_payload.append(int(payload[i:i + 2], 16))\n",
    "        tmp.append(byte_payload)\n",
    "    tmp = pad_sequences(tmp, maxlen=max_len, padding='post', truncating='post', value=256)\n",
    "\n",
    "    return np.array(tmp)\n",
    "\n",
    "\n",
    "def div_256_preprocessing_payload(payloads, max_len=1600):\n",
    "    tmp = []\n",
    "    for payload in tqdm(payloads):\n",
    "        byte_payload = []\n",
    "        for i in range(0, len(payload), 2):\n",
    "            byte_payload.append(int(payload[i:i + 2], 16))\n",
    "        tmp.append(byte_payload)\n",
    "    tmp = pad_sequences(tmp, maxlen=max_len, padding='post', truncating='post', value=256)\n",
    "    tmp2 = []\n",
    "    for data in tqdm(tmp):\n",
    "        tmp2.append(data/256)\n",
    "\n",
    "    return np.array(tmp2)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_preprocessing_payload(payloads, max_len=1600):\n",
    "    tmp = []\n",
    "    for payload in payloads:\n",
    "        byte_payload = []\n",
    "        for i in range(0, len(payload), 2):\n",
    "            byte_payload.append(int(payload[i:i + 2], 16))\n",
    "        tmp.append(byte_payload)\n",
    "    tmp = pad_sequences(tmp, maxlen=max_len, padding='post', truncating='post', value=256)\n",
    "\n",
    "    return to_categorical(tmp)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_Generator():\n",
    "    data = pd.read_pickle(\"E:/full_data/from_2018_8_to_2019_1.pkl\")\n",
    "    temp_X, temp_y = extract(data)\n",
    "    temp_y = np.asarray(temp_y, dtype=np.float32)\n",
    "    bs = 64\n",
    "    while 1:\n",
    "        for i in range(22554): # 64 * 22,553 + remain[45] = 1,443,437 -> # of training samples\n",
    "            tmp_X = one_hot_preprocessing_payload(temp_X[i*bs:(i+1)*bs])\n",
    "            yield tmp_X, temp_y[i*bs:(i+1)*bs]\n",
    "            \n",
    "def one_hot_eval_Generator():\n",
    "    data = pd.read_pickle(\"E:/full_data/from_2019_2_to_2019_3.pkl\")\n",
    "    temp_X, temp_y = extract(data)\n",
    "    temp_y = np.asarray(temp_y, dtype=np.float32)\n",
    "    bs = 64\n",
    "    while 1:\n",
    "        for i in range(11302): # 64 * 11301 + remain[56] = 723,320 -> # of training samples\n",
    "            tmp_X = one_hot_preprocessing_payload(temp_X[i*bs:(i+1)*bs])\n",
    "            yield tmp_X, temp_y[i*bs:(i+1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(data):\n",
    "    temp_payload = []\n",
    "    temp_y = []\n",
    "    for value in data.values():\n",
    "        for j in range(len(value)):\n",
    "            temp_payload.append(value[j][0])\n",
    "            temp_y.append(2 - value[j][1])\n",
    "    return temp_payload, temp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cases = [\"div_256\", \"one_hot\", \"keras_embed\"]\n",
    "    data = pd.read_pickle(\"E:/full_data/from_2018_8_to_2019_1.pkl\")\n",
    "    X, y = extract(data)\n",
    "    train_y = np.asarray(y, dtype=np.float32)\n",
    "    EPOCH = 1\n",
    "    for case in cases:\n",
    "        best_acc = -1\n",
    "        best_epoch = -1\n",
    "        stack = 0\n",
    "        if case == \"div_256\":\n",
    "            print(\"=\"*40+\"div_256\"+\"=\"*40)\n",
    "            train_x = div_256_preprocessing_payload(X)\n",
    "            train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "            model = div_256_RedDNN()\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            for i in range(EPOCH):\n",
    "                print(\"Epoch#\"+str(i+1))\n",
    "                history = model.fit(\n",
    "                    x = {\n",
    "                        'now_pay': train_x,\n",
    "                    }, y=train_y,\n",
    "                    epochs=1, batch_size=64, verbose=1,)\n",
    "                model.save_weights(r\"E:\\full_data\\exp_res\\div_256_ep\"+str(i+1)+\".h5\")\n",
    "                cur_acc = history.history['acc'][0]\n",
    "                if best_acc < cur_acc:\n",
    "                    best_acc = cur_acc\n",
    "                    best_epoch = i+1\n",
    "                    stack = 0\n",
    "                else:\n",
    "                    stack += 1\n",
    "                    if stack == 4:\n",
    "                        print(\"Best Acc : {}, Best Epoch\".format(best_acc, best_epoch))\n",
    "                        break\n",
    "\n",
    "        elif case == \"one_hot\":\n",
    "            print(\"=\"*40+\"one_hot\"+\"=\"*40)\n",
    "            model = one_hot_RedDNN()\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            for i in range(EPOCH):\n",
    "                print(\"Epoch#\"+str(i+1))\n",
    "                history = model.fit_generator(one_hot_Generator(), steps_per_epoch=22554, epochs = 1, verbose=1)\n",
    "                model.save_weights(r\"E:\\full_data\\exp_res\\one_hot_ep\"+str(i+1)+\".h5\")\n",
    "                cur_acc = history.history['acc'][0]\n",
    "                if best_acc < cur_acc:\n",
    "                    best_acc = cur_acc\n",
    "                    best_epoch = i+1\n",
    "                    stack = 0\n",
    "                else:\n",
    "                    stack += 1\n",
    "                    if stack == 4:\n",
    "                        print(\"Best Acc : {}, Best Epoch\".format(best_acc, best_epoch))\n",
    "                        break\n",
    "        elif case == \"keras_embed\":\n",
    "            print(\"=\"*40+\"keras_embed\"+\"=\"*40)\n",
    "            train_x = keras_embedding_preprocessing_payload(X)\n",
    "            model = keras_embedding_RedDNN()\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            for i in range(EPOCH):\n",
    "                print(\"Epoch#\"+str(i+1))\n",
    "                history = model.fit(\n",
    "                    x={'now_pay': train_x,}, y=train_y,\n",
    "                    epochs=1, \n",
    "                    batch_size=64,\n",
    "                    verbose=1,)\n",
    "                model.save_weights(r\"E:\\full_data\\exp_res\\keras_embed_ep\"+str(i+1)+\".h5\")\n",
    "                cur_acc = history.history['acc'][0]\n",
    "                if best_acc < cur_acc:\n",
    "                    best_acc = cur_acc\n",
    "                    best_epoch = i+1\n",
    "                    stack = 0\n",
    "                else:\n",
    "                    stack += 1\n",
    "                    if stack == 4:\n",
    "                        print(\"Best Acc : {}, Best Epoch\".format(best_acc, best_epoch))\n",
    "                        break\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "div_pathes=glob.glob(\"E:/full_data/exp_res/div_*.h5\")\n",
    "one_hot_pathes = glob.glob(\"E:/full_data/exp_res/one*.h5\")\n",
    "keras_pathes = glob.glob(\"E:/full_data/exp_res/kera*.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\"div\", \"one_hot\", \"keras\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================div========================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e7b5516b13449fbf905de6d092f477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=723320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32d4a8ce33f41b8b6a90e2f025ab08f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=723320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch #1 ,  E:/full_data/exp_res\\div_256_ep01.h5\n",
      "723320/723320 [==============================] - 72s 100us/sample - loss: 0.4855 - acc: 0.9041 - precision: 1.0000 - recall: 2.7383e-04\n",
      "Epoch #2 ,  E:/full_data/exp_res\\div_256_ep02.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 3.9636 - acc: 0.3150 - precision_1: 0.1166 - recall_1: 0.9343\n",
      "Epoch #3 ,  E:/full_data/exp_res\\div_256_ep03.h5\n",
      "723320/723320 [==============================] - 72s 99us/sample - loss: 0.8876 - acc: 0.9043 - precision_2: 0.7592 - recall_2: 0.0039\n",
      "Epoch #4 ,  E:/full_data/exp_res\\div_256_ep04.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 0.6453 - acc: 0.7914 - precision_3: 0.0560 - recall_3: 0.0740\n",
      "Epoch #5 ,  E:/full_data/exp_res\\div_256_ep05.h5\n",
      "723320/723320 [==============================] - 72s 99us/sample - loss: 1.1470 - acc: 0.9042 - precision_4: 0.9048 - recall_4: 0.0014\n",
      "Epoch #6 ,  E:/full_data/exp_res\\div_256_ep06.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 4.5436 - acc: 0.3711 - precision_5: 0.1228 - recall_5: 0.9041\n",
      "Epoch #7 ,  E:/full_data/exp_res\\div_256_ep07.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 10.0454 - acc: 0.2195 - precision_6: 0.1053 - recall_6: 0.9522\n",
      "Epoch #8 ,  E:/full_data/exp_res\\div_256_ep08.h5\n",
      "723320/723320 [==============================] - 72s 100us/sample - loss: 2.0588 - acc: 0.9041 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
      "Epoch #9 ,  E:/full_data/exp_res\\div_256_ep09.h5\n",
      "723320/723320 [==============================] - 71s 99us/sample - loss: 2.9471 - acc: 0.8781 - precision_8: 0.4361 - recall_8: 0.9230\n",
      "Epoch #10 ,  E:/full_data/exp_res\\div_256_ep10.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 1.0152 - acc: 0.9043 - precision_9: 0.7392 - recall_9: 0.0040\n",
      "Epoch #11 ,  E:/full_data/exp_res\\div_256_ep11.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 6.0469 - acc: 0.7305 - precision_10: 0.2533 - recall_10: 0.9293\n",
      "Epoch #12 ,  E:/full_data/exp_res\\div_256_ep12.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 0.5955 - acc: 0.8159 - precision_11: 0.1871 - recall_11: 0.2749\n",
      "Epoch #13 ,  E:/full_data/exp_res\\div_256_ep13.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 1.2839 - acc: 0.9042 - precision_12: 0.7850 - recall_12: 0.0012\n",
      "Epoch #14 ,  E:/full_data/exp_res\\div_256_ep14.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 48.6916 - acc: 0.2442 - precision_13: 0.1126 - recall_13: 0.9997\n",
      "Epoch #15 ,  E:/full_data/exp_res\\div_256_ep15.h5\n",
      "723320/723320 [==============================] - 72s 99us/sample - loss: 4.1068 - acc: 0.8349 - precision_14: 0.2800 - recall_14: 0.4588\n",
      "Epoch #16 ,  E:/full_data/exp_res\\div_256_ep16.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 7.3178 - acc: 0.5943 - precision_15: 0.1829 - recall_15: 0.9315\n",
      "Epoch #17 ,  E:/full_data/exp_res\\div_256_ep17.h5\n",
      "723320/723320 [==============================] - 70s 97us/sample - loss: 0.4189 - acc: 0.8766 - precision_16: 0.4300 - recall_16: 0.8813\n",
      "Epoch #18 ,  E:/full_data/exp_res\\div_256_ep18.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 7.4923 - acc: 0.3120 - precision_17: 0.1174 - recall_17: 0.9469\n",
      "Epoch #19 ,  E:/full_data/exp_res\\div_256_ep19.h5\n",
      "723320/723320 [==============================] - 71s 99us/sample - loss: 2.9711 - acc: 0.8618 - precision_18: 0.3816 - recall_18: 0.7100\n",
      "Epoch #20 ,  E:/full_data/exp_res\\div_256_ep20.h5\n",
      "723320/723320 [==============================] - 71s 98us/sample - loss: 18.9694 - acc: 0.2657 - precision_19: 0.1154 - recall_19: 0.9987\n",
      "========================================one_hot========================================\n",
      "Epoch #1 ,  E:/full_data/exp_res\\one_hot_ep01.h5\n",
      "WARNING:tensorflow:From <ipython-input-7-c2f8da93f961>:25: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #2 ,  E:/full_data/exp_res\\one_hot_ep02.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #3 ,  E:/full_data/exp_res\\one_hot_ep03.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #4 ,  E:/full_data/exp_res\\one_hot_ep04.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #5 ,  E:/full_data/exp_res\\one_hot_ep05.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #6 ,  E:/full_data/exp_res\\one_hot_ep06.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #7 ,  E:/full_data/exp_res\\one_hot_ep07.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #8 ,  E:/full_data/exp_res\\one_hot_ep08.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #9 ,  E:/full_data/exp_res\\one_hot_ep09.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #10 ,  E:/full_data/exp_res\\one_hot_ep10.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #11 ,  E:/full_data/exp_res\\one_hot_ep11.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #12 ,  E:/full_data/exp_res\\one_hot_ep12.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #13 ,  E:/full_data/exp_res\\one_hot_ep13.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #14 ,  E:/full_data/exp_res\\one_hot_ep14.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #15 ,  E:/full_data/exp_res\\one_hot_ep15.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #16 ,  E:/full_data/exp_res\\one_hot_ep16.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #17 ,  E:/full_data/exp_res\\one_hot_ep17.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #18 ,  E:/full_data/exp_res\\one_hot_ep18.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #19 ,  E:/full_data/exp_res\\one_hot_ep19.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Epoch #20 ,  E:/full_data/exp_res\\one_hot_ep20.h5\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4231e11c4e744eab89e4acacd73287ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=723320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch #1 ,  E:/full_data/exp_res\\keras_embed_ep01.h5\n",
      "723320/723320 [==============================] - 83s 114us/sample - loss: 0.0319 - acc: 0.9913 - precision_40: 0.9180 - recall_40: 0.9980\n",
      "Epoch #2 ,  E:/full_data/exp_res\\keras_embed_ep02.h5\n",
      "723320/723320 [==============================] - 82s 113us/sample - loss: 0.0157 - acc: 0.9943 - precision_41: 0.9491 - recall_41: 0.9944\n",
      "Epoch #3 ,  E:/full_data/exp_res\\keras_embed_ep03.h5\n",
      "723320/723320 [==============================] - 82s 114us/sample - loss: 0.2004 - acc: 0.9268 - precision_42: 0.5673 - recall_42: 0.9986\n",
      "Epoch #4 ,  E:/full_data/exp_res\\keras_embed_ep04.h5\n",
      "723320/723320 [==============================] - 86s 119us/sample - loss: 0.3904 - acc: 0.8872 - precision_43: 0.4596 - recall_43: 0.9989\n",
      "Epoch #5 ,  E:/full_data/exp_res\\keras_embed_ep05.h5\n",
      "723320/723320 [==============================] - 82s 114us/sample - loss: 0.0100 - acc: 0.9967 - precision_44: 0.9708 - recall_44: 0.9951\n",
      "Epoch #6 ,  E:/full_data/exp_res\\keras_embed_ep06.h5\n",
      "723320/723320 [==============================] - 82s 114us/sample - loss: 0.0645 - acc: 0.9779 - precision_45: 0.8139 - recall_45: 0.9979\n",
      "Epoch #7 ,  E:/full_data/exp_res\\keras_embed_ep07.h5\n",
      "723320/723320 [==============================] - 83s 114us/sample - loss: 0.0315 - acc: 0.9873 - precision_46: 0.8846 - recall_46: 0.9983\n",
      "Epoch #8 ,  E:/full_data/exp_res\\keras_embed_ep08.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0073 - acc: 0.9979 - precision_47: 0.9847 - recall_47: 0.9940\n",
      "Epoch #9 ,  E:/full_data/exp_res\\keras_embed_ep09.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0062 - acc: 0.9982 - precision_48: 0.9872 - recall_48: 0.9936\n",
      "Epoch #10 ,  E:/full_data/exp_res\\keras_embed_ep10.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0101 - acc: 0.9975 - precision_49: 0.9814 - recall_49: 0.9932\n",
      "Epoch #11 ,  E:/full_data/exp_res\\keras_embed_ep11.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0201 - acc: 0.9922 - precision_50: 0.9272 - recall_50: 0.9965\n",
      "Epoch #12 ,  E:/full_data/exp_res\\keras_embed_ep12.h5\n",
      "723320/723320 [==============================] - 82s 114us/sample - loss: 0.0109 - acc: 0.9966 - precision_51: 0.9714 - recall_51: 0.9941\n",
      "Epoch #13 ,  E:/full_data/exp_res\\keras_embed_ep13.h5\n",
      "723320/723320 [==============================] - 83s 114us/sample - loss: 0.0239 - acc: 0.9901 - precision_52: 0.9117 - recall_52: 0.9927\n",
      "Epoch #14 ,  E:/full_data/exp_res\\keras_embed_ep14.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0111 - acc: 0.9957 - precision_53: 0.9616 - recall_53: 0.9953\n",
      "Epoch #15 ,  E:/full_data/exp_res\\keras_embed_ep15.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0164 - acc: 0.9944 - precision_54: 0.9466 - recall_54: 0.9979\n",
      "Epoch #16 ,  E:/full_data/exp_res\\keras_embed_ep16.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0086 - acc: 0.9981 - precision_55: 0.9840 - recall_55: 0.9960\n",
      "Epoch #17 ,  E:/full_data/exp_res\\keras_embed_ep17.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0118 - acc: 0.9965 - precision_56: 0.9902 - recall_56: 0.9729\n",
      "Epoch #18 ,  E:/full_data/exp_res\\keras_embed_ep18.h5\n",
      "723320/723320 [==============================] - 83s 115us/sample - loss: 0.0190 - acc: 0.9928 - precision_57: 0.9325 - recall_57: 0.9974\n",
      "Epoch #19 ,  E:/full_data/exp_res\\keras_embed_ep19.h5\n",
      "723320/723320 [==============================] - 84s 116us/sample - loss: 0.0163 - acc: 0.9938 - precision_58: 0.9414 - recall_58: 0.9980\n",
      "Epoch #20 ,  E:/full_data/exp_res\\keras_embed_ep20.h5\n",
      "723320/723320 [==============================] - 82s 114us/sample - loss: 0.0177 - acc: 0.9932 - precision_59: 0.9358 - recall_59: 0.9978\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(\"E:/full_data/from_2019_2_to_2019_3.pkl\")\n",
    "X, y = extract(data)\n",
    "valid_y = np.asarray(y, dtype=np.float32)\n",
    "history = []\n",
    "for case in cases:\n",
    "    temp_hist = []\n",
    "    if case == \"div\":\n",
    "        print(\"=\"*40+case+\"=\"*40)\n",
    "        valid_x = div_256_preprocessing_payload(X)\n",
    "        valid_x = np.reshape(valid_x, (valid_x.shape[0], valid_x.shape[1], 1))\n",
    "        for i, ep_weight in enumerate(div_pathes):\n",
    "            model = div_256_RedDNN()\n",
    "            print(\"Epoch #\"+str(i+1), \", \", ep_weight)\n",
    "            model.load_weights(ep_weight)\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            valid_hist = model.evaluate({\"now_pay\":valid_x}, valid_y)\n",
    "            temp_hist.append(valid_hist)\n",
    "    elif case == \"one_hot\":\n",
    "        print(\"=\"*40+case+\"=\"*40)\n",
    "        for i, ep_weight in enumerate(one_hot_pathes):\n",
    "            print(\"Epoch #\"+str(i+1), \", \", ep_weight)\n",
    "            model = one_hot_RedDNN()\n",
    "            model.load_weights(ep_weight)\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            valid_hist = model.evaluate_generator(one_hot_eval_Generator(), steps=11302)\n",
    "            temp_hist.append(valid_hist)\n",
    "    elif case == \"keras\":\n",
    "        valid_x = keras_embedding_preprocessing_payload(X)\n",
    "        for i, ep_weight in enumerate(keras_pathes):\n",
    "            print(\"Epoch #\"+str(i+1), \", \", ep_weight)\n",
    "            model = keras_embedding_RedDNN()\n",
    "            model.load_weights(ep_weight)\n",
    "            model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc', Precision(), Recall()])\n",
    "            valid_hist = model.evaluate({\"now_pay\":valid_x}, valid_y)\n",
    "            temp_hist.append(valid_hist)\n",
    "    history.append(temp_hist)\n",
    "\n",
    "pd.to_pickle(history, \"E:/full_data/exp_res/history.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.48551675884916423, 0.90409917, 1.0, 0.00027383046],\n",
       "  [3.9635830789503737, 0.31500304, 0.11664987, 0.9342951],\n",
       "  [0.8875744970314051, 0.9043259, 0.7592068, 0.0038624506],\n",
       "  [0.645299287938226, 0.7914132, 0.055971492, 0.0740207],\n",
       "  [1.1469669226438723, 0.9041904, 0.9047619, 0.0013691523],\n",
       "  [4.543639351813756, 0.37114003, 0.12277199, 0.90405846],\n",
       "  [10.045441943937925, 0.21949483, 0.10532164, 0.952195],\n",
       "  [2.0588214504278897, 0.9040729, 0.0, 0.0],\n",
       "  [2.9470593339308504, 0.8781051, 0.436057, 0.92302483],\n",
       "  [1.0151970489699067, 0.904319, 0.7392473, 0.0039633354],\n",
       "  [6.0468787717413575, 0.73047197, 0.25333259, 0.92930853],\n",
       "  [0.5954901231613873, 0.81588924, 0.18711063, 0.27486813],\n",
       "  [1.2838948084879072, 0.9041572, 0.78504676, 0.0012106189],\n",
       "  [48.69158961979056, 0.24422248, 0.11259937, 0.9996541],\n",
       "  [4.106841410728551, 0.8349071, 0.27998593, 0.4587813],\n",
       "  [7.317781073020298, 0.594275, 0.18291907, 0.931528],\n",
       "  [0.4189292174788925, 0.8765567, 0.43001807, 0.8812873],\n",
       "  [7.492263108298835, 0.31202096, 0.11740174, 0.9469345],\n",
       "  [2.9710986108336526, 0.86180115, 0.381582, 0.7099847],\n",
       "  [18.96944690246711, 0.26573715, 0.11543439, 0.9987173]],\n",
       " [[1.3180494702148455, 0.8911823, 0.22589369, 0.0553714],\n",
       "  [0.3153468329688346, 0.8808439, 0.3697479, 0.34370047],\n",
       "  [0.6683375188795952, 0.5667741, 0.16516663, 0.8672355],\n",
       "  [1.0973408003354441, 0.4580642, 0.14977495, 0.9941775],\n",
       "  [0.2756717424666455, 0.8994539, 0.48698187, 0.90061396],\n",
       "  [0.14537766465689303, 0.9660054, 0.77891785, 0.9014931],\n",
       "  [0.0899960177303762, 0.9696331, 0.8086943, 0.89520943],\n",
       "  [0.3269908965830457, 0.86174166, 0.4016573, 0.9011616],\n",
       "  [0.07733186476441174, 0.9814591, 0.9213018, 0.88206553],\n",
       "  [0.05935967946161055, 0.984202, 0.9326138, 0.9003689],\n",
       "  [0.05630381536853183, 0.9774291, 0.86658835, 0.9038567],\n",
       "  [0.038087115624831636, 0.990451, 0.9183955, 0.98826855],\n",
       "  [0.03945317876838943, 0.98941684, 0.91608363, 0.9793907],\n",
       "  [0.044292274440927364, 0.9880482, 0.97186273, 0.9015075],\n",
       "  [0.037434867827759406, 0.98708457, 0.9379194, 0.92669994],\n",
       "  [0.017626247156318314, 0.9970497, 0.9816374, 0.98772085],\n",
       "  [0.01807826474944293, 0.9967981, 0.97628176, 0.99068975],\n",
       "  [0.020418615511083406, 0.99714094, 0.9798968, 0.99051684],\n",
       "  [0.02509819961738369, 0.9954958, 0.96115655, 0.9931831],\n",
       "  [0.02086668097981692, 0.9967815, 0.97557515, 0.99126625]],\n",
       " [[0.031948513676766134, 0.9912611, 0.9180421, 0.9979967],\n",
       "  [0.0157328704933927, 0.99434, 0.9490756, 0.99435043],\n",
       "  [0.20041890324903472, 0.9268069, 0.5673217, 0.9985732],\n",
       "  [0.3904454236756291, 0.8872477, 0.45964587, 0.9989047],\n",
       "  [0.009950163556652965, 0.99665844, 0.9708103, 0.9950855],\n",
       "  [0.06451593035529539, 0.9779102, 0.8138841, 0.9979246],\n",
       "  [0.031514301925851654, 0.9873486, 0.8846473, 0.99828494],\n",
       "  [0.007324927462869517, 0.9979387, 0.9846527, 0.99400455],\n",
       "  [0.006163999454023319, 0.99815017, 0.9872265, 0.9935722],\n",
       "  [0.010132577718402966, 0.99753636, 0.9813591, 0.9931831],\n",
       "  [0.020079122575112417, 0.99215835, 0.927175, 0.99652666],\n",
       "  [0.01090391561622003, 0.9966239, 0.9713702, 0.99410546],\n",
       "  [0.02390764880902357, 0.99007493, 0.9116779, 0.9927075],\n",
       "  [0.011096720224673, 0.99573773, 0.96161073, 0.99530166],\n",
       "  [0.01639138189161829, 0.9944022, 0.94663876, 0.99789584],\n",
       "  [0.008554147746249064, 0.9980617, 0.9839683, 0.9960222],\n",
       "  [0.01176028495036252, 0.9964732, 0.99015796, 0.9729052],\n",
       "  [0.019027017992130343, 0.99282753, 0.9325195, 0.9974058],\n",
       "  [0.016270740161087937, 0.9938464, 0.9413804, 0.9979967],\n",
       "  [0.01769216255402183, 0.9932243, 0.9358449, 0.99776614]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = div_256_RedDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "now_pay (InputLayer)         [(None, 1600, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1598, 32)          128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 1598, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 1598, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_60  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 865\n",
      "Trainable params: 769\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_embedding_RedDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "now_pay (InputLayer)         [(None, 1600)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 1600, 8)           2056      \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 1598, 32)          800       \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 1598, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 1598, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_61  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,593\n",
      "Trainable params: 3,497\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = one_hot_RedDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "now_pay (InputLayer)         [(None, 1600, 257)]       0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1598, 32)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 1598, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 1598, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_62  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 25,441\n",
      "Trainable params: 25,345\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
